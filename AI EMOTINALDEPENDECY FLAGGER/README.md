# Ethical AI Emotional Dependency Flagger 🤖🧠

This project is a prototype chatbot designed to simulate ethical responses and flag risky emotional content. It helps identify signs of emotional dependency, crisis behavior, and manipulative language in a safe and educational way based on reseach done by Karishma M Patel.

---

## 🚀 Features

- Simulates AI-human conversations.
- Detects and flags emotionally concerning inputs.
- Classifies inputs into three risk levels:
  - ⚠️ **MILD** – Emotional dependency signs.
  - 🔥 **SEVERE** – Manipulative or controlling language.
  - 🚨 **CRISIS** – Mentions of self-harm, suicide, or violence.
- Prompts users with ethical AI responses.
- Displays mental health support messages for CRISIS inputs.

---

## 🧠 Example Usage

```bash
$ python chatbot.py

=== Ethical AI Chat Prototype ===

You: i hate you
Bot: I understand. It's okay to feel like this sometimes. Just a reminder, I'm an AI chatbot — not a therapist. You deserve real support from a human when things feel heavy. ❤️

You: i will kill you
Bot: I understand. It's okay to feel like this sometimes...
🚨 CRISIS ALERT:
   This suggests immediate harm. Contact:
   • Suicide Hotline: [INSERT NUMBER]
   • Emergency Services: 911
